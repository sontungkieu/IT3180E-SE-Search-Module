import os,json
import numpy as np
import onnxruntime
from transformers import AutoTokenizer
from typing import List, Dict, Any
from chromadb import PersistentClient



# ÄÆ°á»ng dáº«n lÆ°u trá»¯ tokenizer vÃ  mÃ´ hÃ¬nh ONNX
TOKENIZER_PATH = "./tokenizer"
ONNX_MODEL_PATH = "./onnx_model/model.onnx"

class LocalEmbeddingFunction:
    """Custom embedding function dÃ¹ng mÃ´ hÃ¬nh local (offline) vá»›i ONNX."""

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        # Táº£i tokenizer tá»« thÆ° má»¥c náº¿u Ä‘Ã£ cÃ³
        if not os.path.exists(TOKENIZER_PATH):
            raise ValueError(f"Tokenizer khÃ´ng tÃ¬m tháº¥y táº¡i {TOKENIZER_PATH}")
        
        # Táº£i mÃ´ hÃ¬nh ONNX tá»« thÆ° má»¥c náº¿u Ä‘Ã£ cÃ³
        if not os.path.exists(ONNX_MODEL_PATH):
            raise ValueError(f"MÃ´ hÃ¬nh ONNX khÃ´ng tÃ¬m tháº¥y táº¡i {ONNX_MODEL_PATH}")
        
        # Load mÃ´ hÃ¬nh ONNX vÃ  tokenizer
        self.session = onnxruntime.InferenceSession(ONNX_MODEL_PATH)
        self.tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)

    def __call__(self, input: List[str]) -> List[List[float]]:
        # Táº¡o input cho mÃ´ hÃ¬nh
        inputs = self.tokenizer(input, padding=True, truncation=True, return_tensors="np")
        
        # Láº¥y cÃ¡c input há»£p lá»‡ tá»« mÃ´ hÃ¬nh ONNX
        ort_inputs = {k: v for k, v in inputs.items() if k in [i.name for i in self.session.get_inputs()]}
        
        # Cháº¡y inference vÃ  láº¥y káº¿t quáº£
        ort_outs = self.session.run(None, ort_inputs)
        
        # TÃ­nh toÃ¡n embeddings báº±ng cÃ¡ch sá»­ dá»¥ng mean pooling
        embeddings = np.mean(ort_outs[0], axis=1)
        
        return embeddings.tolist()



class VectorDatabase:
    """Vector DB cho dá»¯ liá»‡u chunk hÃ³a, dÃ¹ng Chroma + offline embedding."""

    def __init__(self, storage_path: str = "./vector_storage"):
        self.client = PersistentClient(path=storage_path)
        self.embedding_fn = LocalEmbeddingFunction()
        self.collection = self.client.get_or_create_collection(
            name="media_vectors",
            embedding_function=self.embedding_fn
        )

    def get_all_scopes(self) -> List[str]:
        scopes: List[str] = []
        try:
            names = self.client.list_collections()  # â†’ Sequence[str] á»Ÿ chromaâ‰¥0.6.0
            for col in names:
                # Náº¿u col lÃ  string thÃ¬ dÃ¹ng trá»±c tiáº¿p, 
                # náº¿u lÃ  object thÃ¬ láº¥y col.name
                if isinstance(col, str):
                    collection_name = col
                else:
                    collection_name = getattr(col, "name", None)
                if collection_name and collection_name.startswith("scope_"):
                    scopes.append(collection_name[len("scope_"):])
        except Exception as e:
            print(f"Error listing collections: {e}")
        return scopes


    def get_collection_by_scope(self, scope: str):
        """Táº¡o hoáº·c láº¥y collection theo scope."""
        return self.client.get_or_create_collection(
            name=f"scope_{scope}",
            embedding_function=self.embedding_fn
        )

    def add_chunk(self, chunk: Dict[str, Any]) -> Dict[str, Any]:
        """ThÃªm 1 chunk vÃ o collection tÆ°Æ¡ng á»©ng."""
        print("chunk:", chunk)
        if chunk.get("chunk_scope") is None:
            print("errooorrr: chunk_scope is None.",chunk)
            raise ValueError("chunk_scope is None.")
            # return {"status": "error", "message": "chunk_scope is None."}
        try:
            scope = f"scope_{chunk["chunk_scope"]}"
            # scope = chunk.get("chunk_scope")
            collection = self.get_collection_by_scope(scope)
            print("collection name:", collection.name)
            print("chunk:", chunk)
            chunk_text = chunk.get("text", "")
            if not chunk_text.strip():
                print("errooorrr: Empty text.")
                return {"status": "error", "message": "Empty text."}

            chunk_id = f"{scope}_{chunk.get('chunk_id')}_{hash(chunk_text)}"

            chunk_metadata = {
                "location": chunk.get("location"),
                "chunk_source": chunk.get("chunk_source"),
                "chunk_scope": chunk.get("chunk_scope"),
                "chunk_source_type": chunk.get("chunk_source_type"),
                "chunk_id": chunk.get("chunk_id"),
            }
            print("chunk_metadata:", chunk_metadata)
            collection.add(
                documents=[chunk_text],
                metadatas=[chunk_metadata],
                ids=[chunk_id]
            )
            print("add chunk_id ok:", chunk_id)
            return {"status": "success", "chunk_id": chunk_id}

        except Exception as e:
            print("Error adding chunk:", e)
            return {"status": "error", "message": str(e)}

    def semantic_search(self, query: str, scope: str, k: int = 5) -> Dict[str, List[Dict[str, Any]]]:
        """TÃ¬m kiáº¿m semantic vector embedding trÃªn nhiá»u scope cÃ¹ng lÃºc."""
        results_by_scope = {}

        # Láº¥y danh sÃ¡ch táº¥t cáº£ cÃ¡c scope (giáº£ sá»­ báº¡n cÃ³ method nÃ y)
        all_scopes = self.get_all_scopes()  # vÃ­ dá»¥ tráº£ vá» ['scope1', 'scope2', ...]

        # Äáº£m báº£o scope hiá»‡n táº¡i náº±m Ä‘áº§u tiÃªn (tÃ¹y chá»n)
        scope = f"scope_{scope}"
        ordered_scopes = [scope] + [s for s in all_scopes if s != scope]

        for sc in ordered_scopes:
            try:
                collection = self.get_collection_by_scope(sc)
                res = collection.query(
                    query_texts=[query],
                    n_results=k,
                    include=["documents", "metadatas", "distances"]
                )
                chunks = []
                for doc, meta, distance in zip(
                    res["documents"][0],
                    res["metadatas"][0],
                    res["distances"][0]
                ):
                    chunks.append({
                        "text": doc,
                        "location": meta.get("location"),
                        "chunk_id": meta.get("chunk_id"),
                        "chunk_source": meta.get("chunk_source"),
                        "chunk_scope": meta.get("chunk_scope"),
                        "chunk_source_type": meta.get("chunk_source_type"),
                        "similarity_score": round(1 - distance, 4)
                    })
                results_by_scope[sc] = chunks

            except Exception as e:
                # Náº¿u lá»—i thÃ¬ váº«n bÃ¡o vá» scope Ä‘Ã³
                results_by_scope[sc] = [{"status": "error", "message": str(e)}]

        return results_by_scope


    def word_search(self, query: str, scope: str, k: int = 5) -> Dict[str, List[Dict[str, Any]]]:
        """TÃ¬m kiáº¿m theo tá»« khÃ³a (exact match) trÃªn nhiá»u scope cÃ¹ng lÃºc."""
        results_by_scope = {}
        all_scopes = self.get_all_scopes()  # vÃ­ dá»¥ ['scope1', 'scope2', ...]

        # Æ¯u tiÃªn scope hiá»‡n táº¡i, rá»“i má»›i Ä‘áº¿n cÃ¡c scope khÃ¡c
        ordered_scopes = [scope] + [s for s in all_scopes if s != scope]

        for sc in ordered_scopes:
            try:
                collection = self.get_collection_by_scope(sc)
                all_docs = collection.get()
                hits = []
                for doc, meta in zip(all_docs["documents"], all_docs["metadatas"]):
                    if query.lower() in doc.lower():
                        hits.append({
                            "text": doc,
                            "location": meta.get("location"),
                            "chunk_id": meta.get("chunk_id"),
                            "chunk_source": meta.get("chunk_source"),
                            "chunk_scope": meta.get("chunk_scope"),
                            "chunk_source_type": meta.get("chunk_source_type")
                        })
                        if len(hits) >= k:
                            break

                results_by_scope[sc] = hits

            except Exception as e:
                results_by_scope[sc] = [{"status": "error", "message": str(e)}]

        return results_by_scope


# âœ… Test Ä‘Æ¡n giáº£n
if __name__ == "__main__":
    db = VectorDatabase()

    chunk1 = {
        "location": "01:16:25",
        "text": "Tokenizer maps between strings and sequences of integers...",
        "chunk_source": "https://www.youtube.com/watch?v=Rvppog1HZJY&t=3s",
        "chunk_scope": "IT3190E",
        "chunk_source_type": "youtube",
        "chunk_id": 49
    }

    chunk2 = {
        "location": "01:18:00",
        "text": "See you next time.",
        "chunk_source": "https://www.youtube.com/watch?v=Rvppog1HZJY&t=3s",
        "chunk_scope": "IT3190E",
        "chunk_source_type": "youtube",
        "chunk_id": 50
    }

    print("â• Add chunk1:", db.add_chunk(chunk1))
    print("â• Add chunk2:", db.add_chunk(chunk2))

    print("\nğŸ” Semantic Search:")
    results = db.semantic_search("tokenizer", scope="IT3190E")
    print(json.dumps(results, indent=2, ensure_ascii=False))

    print("\nğŸ” Word Search:")
    results = db.word_search("see you", scope="IT3190E")
    print(json.dumps(results, indent=2, ensure_ascii=False))
